{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments_db = pickle.load(open('data/2015_06_06_comments_db.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_sentiments = pickle.load(open('data/2015-06-10-comments_db_with_simple_sentiments.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample evenly from different projects - avoid bias towards single projects with lots of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "df = pd.DataFrame()\n",
    "keys = []\n",
    "comment_index = []\n",
    "comments = []\n",
    "dates = []\n",
    "index = []\n",
    "user = []\n",
    "sentiment = []\n",
    "for key in comments_sentiments:\n",
    "    row = comments_sentiments[key]\n",
    "    for ii in row.keys():\n",
    "        if type(ii) is not int:\n",
    "            continue\n",
    "        if len(row[ii]) == 0:\n",
    "            continue\n",
    "        if len(row[ii]['comment']) == 0 or len(row[ii]['date']) == 0:\n",
    "            continue\n",
    "        keys.append(key)\n",
    "        comment_index.append(ii)\n",
    "        comments.append(row[ii]['comment'])\n",
    "        dates.append(row[ii]['date'])\n",
    "        index.append(row[ii]['index'])\n",
    "        user.append(row[ii]['user'])\n",
    "        sentiment.append(row[ii]['sentiment'])\n",
    "df['keys'] = keys\n",
    "df['comments'] = comments\n",
    "df['dates'] = dates\n",
    "df['index'] = index\n",
    "df['user'] = user\n",
    "df['comment_index'] = comment_index\n",
    "df['sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build sample: half \"negative\" and half \"non-negative\" comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_project_keys = df.groupby('keys').count()['comments'].reset_index()\n",
    "big_project_keys = big_project_keys[big_project_keys['comments'] > 10]\n",
    "big_project_keys.rename(columns ={'comments':'total_comments'},inplace=True)\n",
    "big_projects = pd.merge(df, big_project_keys, how='inner', on='keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_comments = df[df['sentiment'] < 0][['keys','comments','comment_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27102, 3)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly sample 1000 negative comments\n",
    "idx_neg = np.random.choice(range(len(negative_comments)), size=1000, replace=False)\n",
    "df_neg = negative_comments.iloc[idx_neg].copy()\n",
    "df_neg['comments'] = df_neg['comments'].apply(lambda x: regex.sub('',x))\n",
    "#df_neg['comments'] = df_neg['comments'].apply(lambda x: x.encode(\"ascii\", \"ignore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# agument with 1000 fully random samples\n",
    "import re\n",
    "\n",
    "keys = []\n",
    "idx = []\n",
    "comments = []\n",
    "\n",
    "comments_per_project = 1\n",
    "grouped = big_projects.groupby('keys')\n",
    "\n",
    "regex = re.compile('[^a-zA-Z0-9.,! ]')\n",
    "for ii in np.unique(big_projects['keys']):\n",
    "    proj = grouped.get_group(ii)\n",
    "    n_comments = proj.iloc[0]['total_comments']\n",
    "    \n",
    "    idx_sample = np.random.choice(range(len(proj)), size=comments_per_project, replace=False)\n",
    "    \n",
    "    for jj in idx_sample:\n",
    "        row = proj.iloc[jj]\n",
    "        keys.append(ii)\n",
    "        idx.append(jj)\n",
    "        comment = regex.sub('',row['comments'])\n",
    "        #comments.append(comment.encode(\"ascii\",\"ignore\"))\n",
    "        comments.append(comment)\n",
    "        \n",
    "sampled_big_projects = pd.DataFrame()\n",
    "sampled_big_projects['keys'] = keys\n",
    "sampled_big_projects['comment_index'] = idx\n",
    "sampled_big_projects['comments'] = comments\n",
    "\n",
    "sampled_big_projects = sampled_big_projects.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = pd.concat([sampled_big_projects, df_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples.to_csv('Comments_for_sentiment_analysis.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys</th>\n",
       "      <th>comment_index</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>422207</td>\n",
       "      <td>66</td>\n",
       "      <td>Thanks JK I have made the change. Ill have mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>727286</td>\n",
       "      <td>0</td>\n",
       "      <td>Also, have you considered contributing to the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keys  comment_index                                           comments\n",
       "0  422207             66  Thanks JK I have made the change. Ill have mor...\n",
       "1  727286              0  Also, have you considered contributing to the ..."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_big_projects.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_index</th>\n",
       "      <th>comments</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Thank you all so much! Im going to program the...</td>\n",
       "      <td>422207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Also, have you considered contributing to the ...</td>\n",
       "      <td>727286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_index                                           comments    keys\n",
       "0             20  Thank you all so much! Im going to program the...  422207\n",
       "1              0  Also, have you considered contributing to the ...  727286"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_index</th>\n",
       "      <th>comments</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>491000</th>\n",
       "      <td>26</td>\n",
       "      <td>Hello and Happy New Year! congratulations for ...</td>\n",
       "      <td>751441237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491060</th>\n",
       "      <td>86</td>\n",
       "      <td>Backed. I too would like an option for local p...</td>\n",
       "      <td>751441237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comment_index                                           comments  \\\n",
       "491000             26  Hello and Happy New Year! congratulations for ...   \n",
       "491060             86  Backed. I too would like an option for local p...   \n",
       "\n",
       "             keys  \n",
       "491000  751441237  \n",
       "491060  751441237  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load results - only use random samples as I know the method has high precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments_for_sentiment_analysis.csv                        comments_for_mt.csv\r\n",
      "\u001b[31mComments_for_sentiment_analysis_windows_positive_only.csv\u001b[m\u001b[m* random_comments_mt_tech_results.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv('random_comments_mt_tech_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITID</th>\n",
       "      <th>index</th>\n",
       "      <th>comment_index</th>\n",
       "      <th>comments</th>\n",
       "      <th>keys</th>\n",
       "      <th>Worker1</th>\n",
       "      <th>Answer1</th>\n",
       "      <th>Worker2</th>\n",
       "      <th>Answer2</th>\n",
       "      <th>Worker3</th>\n",
       "      <th>Answer3</th>\n",
       "      <th>Worker4</th>\n",
       "      <th>Answer4</th>\n",
       "      <th>Worker5</th>\n",
       "      <th>Answer5</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3FTID4TN8LY766X2LA3ZS73TVV4YLR</td>\n",
       "      <td>448</td>\n",
       "      <td>100</td>\n",
       "      <td>This project had been so heartfelt and excitin...</td>\n",
       "      <td>468214073</td>\n",
       "      <td>A16U1L4R6WV5G2</td>\n",
       "      <td>2</td>\n",
       "      <td>A1T79J0XQXDDGC</td>\n",
       "      <td>2</td>\n",
       "      <td>A3HW4QDJB63OQ2</td>\n",
       "      <td>2</td>\n",
       "      <td>A9K0CV70JWG1W</td>\n",
       "      <td>2</td>\n",
       "      <td>AXMPSUNKUBEIL</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-06-15 07:38:11 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3ZVPAMTJWN3IND7FWOEP7J5OWR2RGB</td>\n",
       "      <td>807</td>\n",
       "      <td>97</td>\n",
       "      <td>Im so friggin thrilled I cant stand it! Thomas...</td>\n",
       "      <td>873229808</td>\n",
       "      <td>A16U1L4R6WV5G2</td>\n",
       "      <td>2</td>\n",
       "      <td>A1T79J0XQXDDGC</td>\n",
       "      <td>2</td>\n",
       "      <td>A1V6P1ZE6Q8YEW</td>\n",
       "      <td>2</td>\n",
       "      <td>A3HW4QDJB63OQ2</td>\n",
       "      <td>2</td>\n",
       "      <td>A9K0CV70JWG1W</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2015-06-15 08:16:54 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            HITID  index  comment_index  \\\n",
       "0  3FTID4TN8LY766X2LA3ZS73TVV4YLR    448            100   \n",
       "1  3ZVPAMTJWN3IND7FWOEP7J5OWR2RGB    807             97   \n",
       "\n",
       "                                            comments       keys  \\\n",
       "0  This project had been so heartfelt and excitin...  468214073   \n",
       "1  Im so friggin thrilled I cant stand it! Thomas...  873229808   \n",
       "\n",
       "          Worker1  Answer1         Worker2  Answer2         Worker3  Answer3  \\\n",
       "0  A16U1L4R6WV5G2        2  A1T79J0XQXDDGC        2  A3HW4QDJB63OQ2        2   \n",
       "1  A16U1L4R6WV5G2        2  A1T79J0XQXDDGC        2  A1V6P1ZE6Q8YEW        2   \n",
       "\n",
       "          Worker4  Answer4        Worker5  Answer5  Avg  \\\n",
       "0   A9K0CV70JWG1W        2  AXMPSUNKUBEIL        2  2.0   \n",
       "1  A3HW4QDJB63OQ2        2  A9K0CV70JWG1W        1  1.8   \n",
       "\n",
       "                      Date  \n",
       "0  2015-06-15 07:38:11 UTC  \n",
       "1  2015-06-15 08:16:54 UTC  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score with current sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import process_data\n",
    "reload(process_data)\n",
    "import nltk\n",
    "stemmer = nltk.stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sent(row):\n",
    "    comment = row['comments']\n",
    "    sentiment = process_data.get_comment_sentiment_simple(comment,stemmer)[0]\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_simple = results.copy(deep=True)\n",
    "results_simple['sentiment_simple'] = results_simple.apply(get_sent,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEPCAYAAACqZsSmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAH4hJREFUeJzt3XucHHWZ7/HPN4TILQmLIJBwUzckIQIaUUAF41HkLnLE\n",
       "4aLIJcc9uqjoQVeUReNlBcVLFM8e3RUQMiJuUFk5CAtyGHEFVAgkYUgw8MKDhouECAQ4XCTP+aN+\n",
       "QyqTnu6uTPdUd9f3/XrVi67qp6ue7gzP1Pyq+vkpIjAzs2oZV3YCZmY29lz8zcwqyMXfzKyCXPzN\n",
       "zCrIxd/MrIJc/M3MKqjU4i/pU5IGJS2VdKmkl5SZj5lZVZRW/CXtBrwfmB0RewKbAMeVlY+ZWZWM\n",
       "L/HYTwDPA1tIegHYAlhZYj5mZpVR2pl/RKwGvgbcDzwAPBYRvygrHzOzKilz2OeVwEeB3YApwFaS\n",
       "3lNWPmZmVVLmsM8+wE0R8SiApJ8AbwB+MBQgyY2HzMw2QkSo3vNlFv/lwNmSNgeeAd4G/HZ4UKM3\n",
       "0M0kzYuIeWXn0S5+f92rl98bVOL9NTxxLnPMfzFwCXArsCRt/pey8jEzq5Iyz/yJiK8AXykzBzOz\n",
       "KvI3fMs1UHYCbTZQdgJtNlB2Am00UHYCbTZQdgJlUydP5iIpennM38ysHZqpnT7zNzOrIBd/M7MK\n",
       "cvE3M6sgF38zswpy8TczqyAXfzOzCnLxNzOrIBd/M7MKcvE3M6sgF38zswpy8TczqyAXfzOzCnLx\n",
       "NzOrIBd/M7MKcvE3M6sgF38zswpy8TczqyAXfzOzCnLxNzOrIBd/M7MKcvE3M6ugUou/pK0lXS5p\n",
       "maS7JO1XZj5mZlUxvuTjfxP4eUQcI2k8sGXJ+Zg1JGkSzJqSrQ0+EBFPlJuRWXGKiHIOLE0Gbo+I\n",
       "V9SJiYjQGKZlVldW+I/bD078a7ZlwXi47Bb/ArBO0kztLPPM/+XAI5IuAvYGbgNOj4inS8zJrIFZ\n",
       "U7LCf9jjacNkWDoFcPG3rlJm8R8PzAY+FBG/kzQfOBP4TD5I0rzc6kBEDIxZhmZmXUDSHGBOodeU\n",
       "OOyzA3BzRLw8rb8JODMijsjFeNjHOoqHfawbdPSwT0Q8JOmPknaPiN8DbwMGy8rHrBkR8YSkW9JQ\n",
       "D77ga92qtDN/AEl7A98DJgD3AqdExOO5533mb2ZWUDO1s9Ti34iLv5lZcc3UTn/D18ysglz8zcwq\n",
       "yMXfzKyCXPzNzCrIxd/MrIJc/M3MKsjF38ysglz8zcwqqOx+/malK9qf3/38rRe4+Ful1WjUtouk\n",
       "ERu1FY0361Qu/lZxRfvzu5+/9QaP+ZuZVZDP/K3iBh+ABbsAk7P1BeOzba2KN+tM7upplecLvtZr\n",
       "3NLZzKyC3NLZzMxqcvE3M6sgF38zswpy8TczqyAXfzOzCnLxNzOrIBd/M7MKcvE3M6ug0ou/pE0k\n",
       "3S7pyrJzMTOritKLP3A6cBfQuV81NjPrMaUWf0k7AYcB3wPcxsHMbIyUfeb/DeATwNqS8zAzq5TS\n",
       "WjpLOgL4c0TcLmlOnbh5udWBiBhoc2pmZl0l1dA5hV5TVldPSV8CTgT+CmwGTAJ+HBHvy8W4q6eZ\n",
       "WUFd09JZ0puBj0fEkcO2u/ibmRXUbS2dy/8tZGZWER1x5j8Sn/mbmRXXbWf+ZmY2RhoWf0nvbmab\n",
       "mZl1j4bDPpJuj4jXNNrWDh72MTMrrpnaOeJ9/pIOJfv27VRJ32LdN3AnAs+3LEszMxtz9b7k9QBw\n",
       "G3BU+u9Q8X8C+Fib8zIzszZqZthn04go5Uzfwz5mZsWNatgnZ19JnwV2y8VHRLxilPmZmVlJmjnz\n",
       "vxv4KLAIeGFoe0Ssam9qPvM3M9sYrTrzfywirm5RTmYdR9J0mHlgtrbsxoi4u1XxBWMnwawp2drg\n",
       "AxHxRJH3Mdb7te7WTPG/QdJ5wE+AZ4c2RsSitmVlNkay4nzsJ+C9z2Vb+veVdN5IRbpIfMHYSXDc\n",
       "fnDiX7MtC3aRdMtoC3W79mvdr5nivx9Z3519hm1/S+vTMRtrMw/MivMRK9OGqbDkQGCEM/Qi8UVi\n",
       "Z03JCvRhj6cNk2HpFLK760ahXfu1btew+EfEnDHIw8zMxlDD4i9pB+CfgKkRcYikPYD9I+KCtmdn\n",
       "1nbLboT+fYGp2Xr/hGxbK+KLxA4+AAt2ASZn6wvGZ9tGq137tW7XzN0+1wAXAWdFxF6SNgVuj4hX\n",
       "tT053+1jY8AXfK3XtGQyF0m3RsQ++X4+ku6IiFe3MNeRju3ib2ZWUKtaOj8p6aW5ne4HPF4n3szM\n",
       "Olwzd/ucAVwJvELSTcB2wDFtzcrMzNqqqZm80jj/7mTN3e4eq14/HvYxMyuuVWP+44HD2bC3z9db\n",
       "kWSDY7v4m5kV1Kr2DlcC/w9YCqxtRWJmZlauZor/1IjYq+2ZmJnZmGnmbp9rJR3c9kzMzGzMNHPm\n",
       "fxPwU0njWDd9Y0TEpPalZWZm7dTMmf/XyZq7bRERE9PSksIvaWdJN0galHSnpI+0Yr9mZlZfM2f+\n",
       "9wODEdGOi73PAx+LiDskbQXcJum6iFjWhmP1vG78Gn+RnNvY/mA2zDw8W1t2VaN25ZIOgJnpuy7L\n",
       "Lo+IX9WJLdLeoch+p8Ie6VrcXUsiYmWd2La0o9iInIvEdt3PcrdppvjfR9bT/2og9SVvza2eEfEQ\n",
       "8FB6/KSkZcAUwMW/oG7s214k5zb2u58Nx34R3puGNPv3l/SPI/0CyArYsV/Nxe8n6eO1ClnBfv5F\n",
       "9jsVjj0RTkz7XbC3pAW1fgG0a/6Bjci5SGzX/Sx3o2aL/33AhLSIrL9/S0naDXgN8JtW77saurFv\n",
       "e5Gc2/X+Zh6eFaQj/pQ27ARLDiebtrRW/DEpfqgz5hRYcgxQ4yy2UO//AvvdY6+s8B/+cNqwPSzd\n",
       "C6hx9t+u+QeK5lwktht/lrtPM/3857U7iTTkczlwekQ8Oey5/PEHImKg3fmYmXUTSXOAOUVeM2Lx\n",
       "l/TNiDhd0pU1no6IeEex9EY8zqbAj4H+iLiixoHmteI4va8b+7YXybld72/ZVdC/P7BTtt6/abZt\n",
       "xPjLoX8/suHJofjLR4gt0vu/wH7vWgIL9ga2z9YXTMi2jTqHonMbFPksCsR2489yudJJ8cDQuqTP\n",
       "NnrNiO0dJL02Im5Lv1FqHCt+uXFprncMARcDj0bEx2o87/YOBXTjRTJf8N3o/fqCr42oVb19PhoR\n",
       "8xtt28gE3wTcCCxh3XWET0XENel5F38zs4JaVfxfnMQlt82TuZiZdahRNXaTdDxwAvDyYeP+E4FH\n",
       "W5OimZmVod7dPjcBD5JN3vJVsls8AdYAi9ucl5mZtVFTk7mUxcM+ZmbFtWQOX0nvkrRC0hOS1qTF\n",
       "V97NzLpYMxd87wWOKKPfjs/8zcyKa8mZP/CQG62ZmfWWZnr73CrpR8AVrN/Y7SftS8vMzNqpmeI/\n",
       "mWwO37cP2+7ib2bWpRoO+0TEyWk5Jb+MRXLWOSTNlvY4O1s0u0HsJOlVM7JFdSf+kTRVmnVotmhq\n",
       "g9iDpT0uyZb6U4tKOlra44ps0dENYudKM2/KFs2tF5vi75F2fzZbdE+D2EukGY9niy5pEHu+NOOR\n",
       "bNH5rcpZ0kAu34EGsQulGWuyRQvrxab470gzHs0WfadB7GnSzEXZotMaxJ4gzfxFtuiEBrHTpT3e\n",
       "ny2a3iC26Z/NXtfwzD99mP8M7BARsyTtBbwjIr7Y9uysIxTpeV+wR3+RvvQHw7Hzczm8LrUZ+Y8a\n",
       "sUdD3/xcDvMlERE/rRE7F/rOgxNfSLHnpdgLRvgs7oG+XeG9aUv/rpLuiYi/rRF7CfQdn4s9Pu37\n",
       "fTViz4e+D8B70x0Y/R9IsR8eTc5Zse97Yy6HN0oaiIg5NWIXQt87c7HvlLQwIt49wmfxHeibm4uf\n",
       "m/L4QI3Y06DvHDgxTQq14JwU+z9rxJ4Afd/I/ft9I8VeWiO2yHwFnicgp5lhn38FPgEM/VZfCvwQ\n",
       "cPGvjCI974v0Yi/Ul/49KYdc7JL3ABsUf5h5UpbDEY+kDdvB0pOADYo/zJibFdEjHksbtoYlc4Ga\n",
       "xR+m7ZwVuyNz227fuXbs9KNS7NAseONg8VEjxB6XFf4jU2FiPCw+Dtig+BfLedr+NfLdf4QcDtkw\n",
       "dvEhtWMBpr87xedzfjewQfFPOa+FI4Z+DialnDco/jDj1PTvtzpt2AaWnApsUPyLzUHgeQLymrnb\n",
       "Z4uIeHGClcjuDX2+TryZmXW4Zs78H5H04p+0ko4ha/tglVGk532RXuyF+tL/APpfty62f9NsW83Y\n",
       "i2HBfLLWJCmHZRfXjl1+ASw4D9g6xW6SbRvJij9C/67r1vvTtlru/nfoP54XT7L607aasZdB/wd4\n",
       "8f/JfmXbRpvzipuh/43D8r15hByugf53rh979zW1YwHuXgj9c3M5p20j5nwOkMbZF4wbOeflF8KC\n",
       "bwDbpNjx2bZaisxB4HkC1hMRdRfglcD1wNPAA8Cvgd0ava4VC+kPDS/lL8BsmHl2tjC7QewkmDUj\n",
       "W5jUIHYq7HFotjC1QezBMPOSbOHgBrFHw8wrsoWjG8TOhRk3ZQtzm/gs7oFpz2YL9zSIvQSmP54t\n",
       "XNIg9nyY/ki2cH6rcgYGcvkONIhdCNPXZAsLm/gsvgPTH80WvtMg9jSYsShbOK1B7Akw4xfZwgkN\n",
       "YqfDzPdnC9Nb9bPZzUsztbPp3j5pqkVFxJqmXtAC/oavmVlxrert89F0S9RTwHxJixrdZmdmZp2t\n",
       "mQu+p0Z2K9Tbycbg3gec29aszMysrZop/kN/OhwOLIiIO9uYj5mZjYFmiv9tkq4FDgOuSUNAaxu8\n",
       "xszMOlgzLZ03AV4N3BsRj0l6KdldGSPcktfC5HzB18yssJZM4F4mF38zs+Ja1c/fzMx6jIu/mVkF\n",
       "NVX8JR0g6ZT0eDtJL2/FwSUdIml5miP4k63Yp5mZNdbMl7zmAf8AfCptmkDWxGNU0oXkbwOHAHsA\n",
       "x0uaOdr9doNO6D9epI9+ii/SS7/I+ztDmjmYLTqjQWyRfve35nrY39ogdmUutkZH0Q3iV+fiV5cU\n",
       "e38u9v4GsQ/mYuv25ZK0Khe7ql5sil+Ui6/R5XW92M9JM/6QLfpcg9givf+b/nmzdZpp7HY08Brg\n",
       "NoCIWClpYguO/Xqyvih/AJB0GXAU0NPzBXdC//EiffRTfJFe+kXe3xnQ93l4b7p1uP/zqW/712rE\n",
       "Ful3fyv07Z3rM7+3pFsjYp8asSuh72W52JdJWhkRNX8hZkW5b2IufqKk1RGxzRjG3g99O+Zid5R0\n",
       "f0TsUiP2QejbNhe7raQHI2LHGrGroG9yLnaypFURse0In8Ui6NszF7+npEURscFkP1mx7zsz9299\n",
       "Zvr3+2yN2CK9/5v+ebP1NVP8n42ItVJ24VjSli069lQg3w3xT8C+Ldp3B+uE/uNF+uhDwV76Bd7f\n",
       "jFOzYnDkk2nDVqlv+wbFv1i/+2l71uhhv2ft9zZt2xqxNYtdit+yRvwI/0+0LXb7GrHbjxC7TY3Y\n",
       "DX6hpNiJNWLrnOhNm1Ujflbt2OknpX/rZ9KGzWDxScAGxb9Y7/8iP2+W10zxXyjpu8DWkv4OOBX4\n",
       "XguO3dQ9pmnYachARAy04NhmZj1D0hxgTpHXNCz+EXGepLcDa4DdgbMj4rqNSXCYlUB+BqSdyc7+\n",
       "hx9/XguO1UE6of94kT76ULCXfoH3t/xC6P88sFWKHTdy3/Yi/e5XLIX+vdet96dtNWNXQf/LhsXW\n",
       "Gete8RT0586G+9O2MY19GPp3HBb78Aixq6F/22GxI1xPWLEG+icPi63TxXfFIPTn/qLqT9tqufti\n",
       "6D8T2CzFjsu21VKk93+Rn7felU6KB4bWJdX4i2p9pX3JS9J4sj/N3ko2T8BvgeMjYlkupie/5JWN\n",
       "U848MFtbdmO98cls3H/WlGxt8IHRjvfn9js1G/4BuGvJSOP9ufiDs+EfgGU/qDXen4st8v7OyIZ/\n",
       "AJZfWGu8Pxd7fjb8A3D3ZbXG+3Oxt2bDPwArltYa78/FrsyGfwBWrBppvD8XvzobpgFY8VStcfkx\n",
       "iL0/G/4BWPFwrfH+XOyD2fAPwIrVtcb7c7GrsuEfgBVrRhrvz8UvyoZ/AFYM1hrvz8V+Lhv+Abj7\n",
       "4lrj/bnY07LhH4DlF9Qa78/FNv3zVhWj+oavpCcZeWgmImLUd55IOhSYD2wCXBAR5wx7vieLv5lZ\n",
       "O7m9g5lZBTVTO5u54Iuk2cABZN08fx0Rde/nNTOzztbMl7w+A1xMNpHLdsBFks5ud2JmZtY+zbR0\n",
       "/j2wV0Q8k9Y3BxZHxO5tT87DPmZmhTVTO5vp7bMS2Dy3vhk1bsk0M7Pu0cyY/xPAoLLZvAAOAn6b\n",
       "eqtERHykbdmZmVlbNDPsc3KdpyMiRviixuh52MfMrDjf6mlmVkEtGfOXdKSk2yX9RdKatLTkW6Zm\n",
       "ZlaOZoZ97iVr63xnRKwdk6zWHdtn/gUUaQWxEe0dZsPMw7O1ZVfV+65HwdgiORdpG1GkHUXRz+LT\n",
       "MOOUbG35RRHxpTqxRT6LtrQ0kHQ0zExtFZZdHBE/rRPblnYiNrZa9SWvPwGDY134rZgivf83op//\n",
       "bDj2i7l+/vtL+sdahaxgbJGci8wTUGT+gaKfxaeh7+xcX/qzU6/5DX4BFPws2tLDPiv8ffNzn/H8\n",
       "tN8NfgEU+few7tdM8f8kcLWkG4D0w0ZExNfbl5YVV6T3f+F+/oenfv5Dt/juBEsOB2qcxRaJLZJz\n",
       "kb7tReYfKPpZzDgl9aV/Om3YApacAtQ4+y/yWbSrh/3Mk7LP+IhH0obtYOlJQI2z/3bNH2GdqJni\n",
       "/wWyds6bkU3haGZmXa6Z4r9jRBzU9kxslIr0/i/cz/8q6N8f2Clb79802zba2CI5F+nbXmT+gaKf\n",
       "xfKLoP9sYIu073HZtpp5FPgs2tXDftnFsGA+WWsWss942Qi3Z7dr/gjrRM1c8P0KcH29C2bt4gu+\n",
       "xfiC73qxvuC7LtYXfCumJff5p77+W5CN96cLV63p59+Ii7+ZWXEtudsnIrZqXUpmZtYJRiz+kmZG\n",
       "xLLUy38D7ulvZta96k3j+K8R8X5JA9SYzjEi3tLm3DzsY2a2Edzbx8ysgkbV20fS6yTtmFs/SdLP\n",
       "JH1L0jatTNTMzMZWvcZu/wI8CyDpQOBcsukcn0jPmZlZl6p3t8+4iFidHh8LfDcifgz8WNLi9qdm\n",
       "ZmbtUu/MfxNJm6bHbwNuyD3XzDeDzcysQ9Ur4j8EfilpFfA08CsASdOAx0Z7YEnnAUeQfXnsXuCU\n",
       "iHi8/qvMzKwV6t7tI2l/YAfg2oh4Km3bHdhqtPf5SzqIrG3EWknnAkTEmcNifLdPh+jlr/1vRHuH\n",
       "Ii0pevZzs8416m/4RsTNNbb9frSJpf1cl1v9DfCuVuzXWq+X+7xvRD//InMQ9OznZt2vU8buTyUb\n",
       "ZrKO1Mt93ov28y/yWfTy52bdrq3FX9J1ZMNGw306Iq5MMWcBz0XEpSPsY15udSAiBlqdp5lZN5M0\n",
       "B5hT5DVtLf6N5gGQdDJwGPDWOvuY19qsrLhe7vNetJ9/kc+ilz836yTppHhgaF3SZxu9prT2DpIO\n",
       "Ab4GvDkiVo0Q4wu+HaKXL1z6gq/1mo7u7SNpBdm0kENfJLs5Iv5+WIyLv5lZQR1d/Jvh4m9mVtyo\n",
       "GruZmVnvcvE3M6sgF38zswpy8TczqyAXfzOzCnLxNzOrIBd/M7MKcvE3M6sgF38zswpy8TczqyAX\n",
       "fzOzCnLxNzOrIBd/M7MKcvE3M6sgF38zswpy8TczqyAXfzOzCnLxNzOrIBd/M7MKcvE3M6sgF38z\n",
       "swpy8TczqyAXfzOzCiq1+Es6Q9JaSduUmYeZWdWML+vAknYGDgL+b1k5VJmkSTBrSrY2+EBEPFFu\n",
       "RmY2lkor/sDXgX8A/r3EHCopK/zH7Qcn/jXbsmAXSbf4F4BZdZRS/CUdBfwpIpZIKiOFips1JSv8\n",
       "hz2eNkyGpVMAF3+zimhb8Zd0HbBDjafOAj4FvD0fXmc/83KrAxEx0Ir8zMx6haQ5wJxCr4mItiQz\n",
       "4gGlVwHXA0+nTTsBK4HXR8Sfh8VGRPhPgxarMewzHi7zsI9Zj2imdo558d8gAek+4LURsbrGcy7+\n",
       "beILvma9q5naWeYF3yHl/vapqFTsXfDNKqr0M/96fOZvZlZcM7XT3/A1M6sgF38zswpy8TczqyAX\n",
       "fzOzCnLxNzOrIBd/M7MKcvE3M6sgF38zswrqhG/4mrWc21eY1efibz3H8xWYNebibz3I8xWYNeIx\n",
       "fzOzCvKZv/WgwQdgwS7A5Gx9wfhsm5kNcVdP60m+4GtV1hWTudTj4m9mVpxbOpuZWU0u/mZmFeTi\n",
       "b2ZWQS7+ZmYV5OJvZlZBLv5mZhXk4m9mVkGlFX9JH5a0TNKdkr5cVh5mZlVUSvGX9BbgHcBeEfEq\n",
       "4Ktl5FE2SXPKzqGd/P66Vy+/N+j999eMss78PwicExHPA0TEIyXlUbY5ZSfQZnPKTqDN5pSdQBvN\n",
       "KTuBNptTdgJlK6v4TwMOlHSLpAFJ+5SUh5lZJbWtq6ek64Adajx1Vjru30TEfpJeB/wb8Ip25WJm\n",
       "ZusrpbGbpKuBcyPil2n9HmDfiHh0WFzndp0zM+tgjRq7ldXP/wrgvwC/lLQ7MGF44YfGyZuZ2cYp\n",
       "q/hfCFwoaSnwHPC+kvIwM6ukju7nb2Zm7dHx3/CV9AVJiyXdIel6STuXnVMrSTovfdltsaSfSJpc\n",
       "dk6tIundkgYlvSBpdtn5tIqkQyQtl7RC0ifLzqeVJF0o6eH0V3nPkbSzpBvSz+Wdkj5Sdk6tJGkz\n",
       "Sb9J9fIuSeeMGNvpZ/6SJkbEmvT4w8DeEfHfSk6rZSQdBFwfEWslnQsQEWeWnFZLSJoBrAW+C5wR\n",
       "EYtKTmnUJG0C3A28DVgJ/A44PiKWlZpYi0g6AHgSuCQi9iw7n1aTtAOwQ0TcIWkr4Dbgnb3y7wcg\n",
       "aYuIeFrSeOA/gY9HxH8Oj+v4M/+hwp9sBawqK5d2iIjrImJtWv0NsFOZ+bRSRCyPiN+XnUeLvR64\n",
       "JyL+kL6keBlwVMk5tUxE/Ar4S9l5tEtEPBQRd6THTwLLgCnlZtVaEfF0ejgB2ARYXSuu44s/gKR/\n",
       "knQ/cBJwbtn5tNGpwM/LTsLqmgr8Mbf+p7TNuoyk3YDXkJ109QxJ4yTdATwM3BARd9WKK+tun/XU\n",
       "+ULYpyPiyog4CzhL0pnAN4BTxjTBUWr0/lLMWcBzEXHpmCY3Ss28tx7T2eOk1pQ05HM5cHr6C6Bn\n",
       "pJGEV6frh/8haU5EDAyP64jiHxEHNRl6KV14Ztzo/Uk6GTgMeOuYJNRCBf7tesVKIH/Twc5kZ//W\n",
       "JSRtCvwY6I+IK8rOp10i4nFJVwH7AAPDn+/4YR9J03KrRwG3l5VLO0g6BPgEcFREPFN2Pm3UK1/Y\n",
       "uxWYJmk3SROAY4GflZyTNUmSgAuAuyJiftn5tJqkbSVtnR5vDhzECDWzG+72uRyYDrwA3At8MCL+\n",
       "XG5WrSNpBdmFmaGLMjdHxN+XmFLLSDoa+BawLfA4cHtEHFpuVqMn6VBgPtnFtAsiYsTb6bqNpB8C\n",
       "bwZeCvwZ+ExEXFRuVq0j6U3AjcAS1g3hfSoirikvq9aRtCdwMdmJ/ThgQUScVzO204u/mZm1XscP\n",
       "+5iZWeu5+JuZVZCLv5lZBbn4m5lVkIu/mVkFufibmVWQi791DElrJS3IrY+X9IikKyWdLOn2tDwn\n",
       "aUl6/KUycy5C0mRJH8ytT5G0sM3H3FXS8e08hnUn3+dvHUPSGmAF8IaIeCZ9mepLwB8j4h25uPuA\n",
       "10ZEzW6FnSo1ErtyLFslS5pD1k77yLE6pnUHn/lbp/k5cHh6fDzwQwq0hkhtF26UdFta9k/bfyjp\n",
       "sFzc9yX9V0mbS/q3NLnHTyTdIum1NfZ7bopZLOm8tG07SZdL+m1a3pC2z0uTotwg6d40DwVkHWlf\n",
       "mf5i+XI6K1+aXnOypCskXSvpPkkfkvRxSYsk3Szpb1LcKyVdLenW9D6n597PNyX9Oh3zXbljHpCO\n",
       "eXqzn6NVQER48dIRC7AG2BNYCLyErCfJm8nOlvNx9wHbjLCPzYGXpMfTgN+lx+8Evp8eTwDuT8f4\n",
       "OPC/0vZZwPPA7GH7fCmwPLc+Kf33UuCN6fEuZP1iAOaRTaKxaXrtKrJWELsCS3P72W1oHTiZ7K+e\n",
       "LVnXDuPv0nNfJ+s+CXA98Lfp8b5kEwEBfB/4UXo8E1iRHm/w+XnxEhGd0dXTbEhELE3DI8cDV23E\n",
       "LiYA35a0N1k/qN3T9muAb6ZmbIcCv4yIZyW9kaxPDxExKGlJjX0+Bjwj6QLgf6cFstm8Zma9wgCY\n",
       "KGlLsp4xV0U22cujkv4MbE/jv2BuiIingKckPQYMtcReCuyV9v0GYGHumBPSfwO4Ir2PZZK2T9t7\n",
       "paGetZiLv3WinwFfJTtr3a7gaz8GPBgRJ6YpF58BiOwawgBwMNBHNpw0pG6BjIgXJL2erOX2McCH\n",
       "0mMB+0bEc/n4VJjz216guf/Xns09XptbX5tePw74S0S8ZoTX54/pom91eczfOtGFwLyIGNyI104C\n",
       "HkqP30c23DLkR2SzpR1A9pcAwK/JfhkgaQ+yYaf1pDPurSPiauB/AHunp64FPpKL23v4a4dZA0ws\n",
       "8F5e3DW8OKXpfZKOSceTpL3adEzrcS7+1kkCICJWRsS3c9uG35JW7xa1fwZOUjaN3XSyyciHXAsc\n",
       "CFwXEX/NxW8naRD4AjBINt6eNxG4UtJi4Fdkf11AVvj3SReBB4H/Xi/HiHgU+LWkpZK+POy9DX+f\n",
       "wx8Prb8HmJve353AO+q8BmAx8IKkO3zB1/J8q6dVmqRxwKZp/P+VwHXA7rlfDmY9yWP+VnVbAv9H\n",
       "2dR+IpssyIXfep7P/M3MKshj/mZmFeTib2ZWQS7+ZmYV5OJvZlZBLv5mZhXk4m9mVkH/H0X6vBkF\n",
       "4C4eAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141375990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(results_simple['Avg'],results_simple['sentiment_simple'],alpha=0.2);\n",
    "plt.xlabel('MT avg sentiment');plt.ylabel('Simple sentiment');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp = len(results_simple[(results_simple['Avg']==1) & (results_simple['sentiment_simple']==1)])\n",
    "fp = len(results_simple[(results_simple['Avg']==1) & (results_simple['sentiment_simple']==1)])\n",
    "tn = len(results_simple[(results_simple['Avg']==1) & (results_simple['sentiment_simple']==1)])\n",
    "fn = len(results_simple[(results_simple['Avg']==1) & (results_simple['sentiment_simple']==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like \"wait\" needs a lot of context: 'can't wait' is good, but 'waiting' is bad.  For now just drop \"wait\" from the blacklist\n",
    "\n",
    "\"Lately\" stems to \"Late\", which is very different meaning.  Also, \"Sorry\" may not be as negative - perhaps weight depending on if it's a backer or creator comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt_positive_simple_negative = results_simple[(results_simple['sentiment_simple']==0) & (results_simple['Avg']>0)].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mt_positive_simple_negative.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mt_positive_simple_negative[['comments','sentiment_simple','Avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Mattias. Sorry to hear that! We will check up on it first thing Monday and make sure you get your wind meter. Thanks a lot for your patience!!'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_positive_simple_negative.loc[525]['comments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of problem is \"not received\" gets split up - we need to know the most predictive bigrams and keep those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mt_negative_simple_positive = results_simple[(results_simple['sentiment_simple']>0) & (results_simple['Avg']<0)].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build stop words list - pool by project and remove single words with high idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_simple_nb = results_simple.copy(deep=True)\n",
    "results_pos_neg = pd.concat([results_simple_nb[results_simple_nb['Avg']<0],results_simple_nb[results_simple_nb['Avg']>0.5]]).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 18)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pos_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_comment(comment):\n",
    "    return word_tokenize(comment.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = [x for x in stopwords.words('english') if x != 'not']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.63%\n",
      "Accuracy on training data: 0.84\n",
      "Accuracy on test data:     0.79\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True, min_df=2, # occur in at least 5 comments\n",
    "                             tokenizer=word_tokenize,\n",
    "                             ngram_range=(2,2),\n",
    "                             stop_words=stop_words + ['!', ',', '.', '?'])\n",
    "\n",
    "# build features\n",
    "vectorizer.fit(results_pos_neg['comments'].values);\n",
    "\n",
    "# convert comments to bag of words\n",
    "X = vectorizer.fit_transform(results_pos_neg['comments'])\n",
    "X = X.toarray() # dense array\n",
    "\n",
    "# convert sentiments to binary: predict negative vs neutral/positive\n",
    "Y = (results_pos_neg['Avg'] < 0).values.astype(np.int) # negative reviews count as +1\n",
    "\n",
    "# run model\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "clf = MultinomialNB(alpha=1, fit_prior=True).fit(xtrain, ytrain)\n",
    "\n",
    "print \"Accuracy: %0.2f%%\" % (100 * clf.score(xtest, ytest))\n",
    "\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(fresh | word)\n",
      "            not work 0.22\n",
      "        not received 0.22\n",
      "          months ago 0.22\n",
      "             ... ... 0.22\n",
      "          would nice 0.19\n",
      "Bad words\t     P(fresh | word)\n",
      "           cant wait 0.96\n",
      "     looking forward 0.95\n",
      "             im glad 0.89\n",
      "            got mine 0.89\n",
      "          thank much 0.89\n"
     ]
    }
   ],
   "source": [
    "words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "x = np.eye(xtest.shape[1])\n",
    "probs = clf.predict_log_proba(x)[:, 1]\n",
    "ind = np.argsort(probs)\n",
    "\n",
    "ii=5\n",
    "good_words = words[ind[-ii:]]\n",
    "bad_words = words[ind[:ii]]\n",
    "\n",
    "good_prob = probs[ind[-ii:]]\n",
    "bad_prob = probs[ind[:ii]]\n",
    "\n",
    "print \"Good words\\t     P(fresh | word)\"\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print \"%20s\" % w, \"%0.2f\" % (1 - np.exp(p))\n",
    "    \n",
    "print \"Bad words\\t     P(fresh | word)\"\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print \"%20s\" % w, \"%0.2f\" % (1 - np.exp(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_bigrams = ['cant wait', 'not wait', 'looking forward', 'got mine', 'wait get', 'thank much', 'im glad', 'really excited', 'congrats guys', 'wait see']\n",
    "bad_bigrams = ['took money', 'still waiting', 'months ago', 'months since', 'hasnt arrived', 'not arrived', 'not received' ]\n",
    "bad_unigrams = ['refund','doubt']\n",
    "good_unigrams = ['congrats', 'goal', 'congratulations', 'glad', 'excited', 'fund', 'arrived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to fit LDA word clusters to sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seriously, this is one of the best ways to lose supporters and possible supporting companies... Unexpected delays, bad communication have time to update Trivia but no time to update the new progress and release update, continuous overoptimistic timeline Yes! next week! No, sorry, the week after next week! Sorry again...... Somethings are ok for a community but not ok for a company...\n"
     ]
    }
   ],
   "source": [
    "example_comment = results.sort('Avg',ascending=True).iloc[8]['comments']\n",
    "print example_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim.models.ldamodel as ldamodel\n",
    "lda_backer = ldamodel.LdaModel.load('lda_grouped_v2/lda_backer')\n",
    "\n",
    "backer_data = pickle.load(open('lda_grouped_v2/data_backer.p','rb'))\n",
    "\n",
    "corpus=backer_data['corpus']\n",
    "dictionary = backer_data['dictionary']\n",
    "id2word = backer_data['id2word']\n",
    "stop_words = backer_data['stop_words']\n",
    "processed_comments = backer_data['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    }
   ],
   "source": [
    "from gensim.similarities import MatrixSimilarity\n",
    "index = MatrixSimilarity(lda_backer[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataframe: topic_number x word index, elements are P(word|topic)\n",
    "topic_df_backer = pickle.load(open('lda_grouped_v2/topic_df_backer.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_comment_2(comment):\n",
    "    tok = word_tokenize(comment)\n",
    "    stop = [word for word in tok if (not word in stop_words_from_web.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment_stopped = [word for word in example_comment\n",
    "alphadic.doc2bow(txt) for txt in corp_stopped]\n",
    "#lda_backer.update(example_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If the exoskeleton is the only thing on backorder.... why would everything else be held ANOTHER month!!!! This is pretty outrageous ODT... you guys DESTROYED your goal of 30K by 4 TIMES THAT AMOUNT! And of course you guys still havent responded to any of this negative feedback from your backers.... last time I ever support this company through kickstarter... weak'"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inferred directly from word counts\n",
    "# index is command-line index, NOT LDA-vis index\n",
    "topic_probs_df = pd.read_excel('lda_grouped_v2/topic_probs_backers.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 4)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_probs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_vis</th>\n",
       "      <th>topic_cmd</th>\n",
       "      <th>topic_fraction</th>\n",
       "      <th>topic_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>11.4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>10.6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_vis  topic_cmd  topic_fraction  topic_sentiment\n",
       "0          1         15            11.4               -1\n",
       "1          2         23            10.6               -1\n",
       "2          3         26             7.8                1"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_probs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# convert words to vector rep\n",
    "word_to_index = defaultdict(dict)\n",
    "for key in dictionary:\n",
    "    word = dictionary[key]\n",
    "    word_to_index[word] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40000000000000002"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_probs_df.iloc[get_frame_index_from_cmd(8,topic_probs_df)]['topic_fraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we need to reference the topic_cmd index, because this is what word_to_index uses\n",
    "def get_frame_index_from_cmd(cmd_index, topic_probs):\n",
    "    # find frame index that corresponds to the given cmd index\n",
    "    return topic_probs[topic_probs['topic_cmd']==cmd_index]['topic_vis'].values[0] - 1\n",
    "\n",
    "# assign topic probabilities; topic_probs = p(topic)\n",
    "def get_topic_probs_word(word, word_to_index, df, topic_probs):\n",
    "    n_tops = df.shape[1]\n",
    "    index = word_to_index[word]\n",
    "    \n",
    "    # get p(word|topic)\n",
    "    if type(index) is not int: # word not present - no information on topic\n",
    "        probs = 1/n_tops * np.ones(n_tops) # no information on word content\n",
    "    else:\n",
    "        probs = df.loc[index] # prob over all topics\n",
    "    \n",
    "    # convert to p(topic) = 1/N * p(word|topic)p(topic)\n",
    "    p_topic = []\n",
    "    for ii in range(n_tops):\n",
    "        frame_index = get_frame_index_from_cmd(ii, topic_probs)\n",
    "        p_topic.append( probs[ii] * topic_probs.iloc[frame_index]['topic_fraction']/100)\n",
    "        \n",
    "    p_topic = p_topic / np.sum(p_topic) # rescale so we don't need to know p(word)\n",
    "    \n",
    "    return p_topic\n",
    "\n",
    "\n",
    "def get_topic_probs_comment(comment, word_to_index, df, topic_probs, tokenized=True):\n",
    "    if not tokenized:\n",
    "        comment = word_tokenize(comment)\n",
    "    n_tops = df.shape[1]\n",
    "    log_word_array = np.zeros(n_tops)\n",
    "    for word in comment:\n",
    "        p_word = get_topic_probs_word(word, word_to_index, df, topic_probs)\n",
    "        log_word_array = log_word_array + np.log(p_word)\n",
    "    prob_word = np.exp(log_word_array)\n",
    "    return nlog_word_array\n",
    "# sentiment = \\sum_topic p(topic|word)*s(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec_bow = dictionary.doc2bow('refund'.lower().split())\n",
    "vec_lda = lda_backer[vec_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_backer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.016666666666666659),\n",
       " (1, 0.016666666666666659),\n",
       " (2, 0.016666666666666659),\n",
       " (3, 0.016666666666666659),\n",
       " (4, 0.016666666666666659),\n",
       " (5, 0.016666666666666659),\n",
       " (6, 0.016666666666669272),\n",
       " (7, 0.016666666666666659),\n",
       " (8, 0.016666666666666659),\n",
       " (9, 0.016666666666666659),\n",
       " (10, 0.016666666666673633),\n",
       " (11, 0.016666666666666659),\n",
       " (12, 0.016666666666666659),\n",
       " (13, 0.016666666666666659),\n",
       " (14, 0.016666666666666659),\n",
       " (15, 0.016666666666666691),\n",
       " (16, 0.016666666666666659),\n",
       " (17, 0.51666666666662231),\n",
       " (18, 0.016666666666666659),\n",
       " (19, 0.016666666666666659),\n",
       " (20, 0.016666666666666659),\n",
       " (21, 0.016666666666666659),\n",
       " (22, 0.016666666666666659),\n",
       " (23, 0.016666666666700997),\n",
       " (24, 0.016666666666666868),\n",
       " (25, 0.016666666666666663),\n",
       " (26, 0.016666666666666659),\n",
       " (27, 0.016666666666666694),\n",
       " (28, 0.016666666666666659),\n",
       " (29, 0.016666666666666659)]"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_backer[dictionary.doc2bow(['refund'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0, p = 0.044955\n",
      "topic 1, p = 0.048951\n",
      "topic 2, p = 0.042957\n",
      "topic 3, p = 0.00699301\n",
      "topic 4, p = 0.020979\n",
      "topic 5, p = 0.026973\n",
      "topic 6, p = 0.001998\n",
      "topic 7, p = 0.001998\n",
      "topic 8, p = 0.003996\n",
      "topic 9, p = 0.001998\n",
      "topic 10, p = 0.0609391\n",
      "topic 11, p = 0.002997\n",
      "topic 12, p = 0.035964\n",
      "topic 13, p = 0.010989\n",
      "topic 14, p = 0.03996\n",
      "topic 15, p = 0.113886\n",
      "topic 16, p = 0.027972\n",
      "topic 17, p = 0.00999001\n",
      "topic 18, p = 0.025974\n",
      "topic 19, p = 0.000999001\n",
      "topic 20, p = 0.00999001\n",
      "topic 21, p = 0.032967\n",
      "topic 22, p = 0.0599401\n",
      "topic 23, p = 0.105894\n",
      "topic 24, p = 0.002997\n",
      "topic 25, p = 0.0509491\n",
      "topic 26, p = 0.0779221\n",
      "topic 27, p = 0.0709291\n",
      "topic 28, p = 0.044955\n",
      "topic 29, p = 0.011988\n"
     ]
    }
   ],
   "source": [
    "a = get_topic_probs_comment('great', word_to_index, topic_df_backer, topic_probs_df,tokenized=False)\n",
    "for ii, p in enumerate(np.exp(a)/np.sum(np.exp(a))):\n",
    "    print 'topic %d, p = %g' % (ii,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04495504,  0.04895105,  0.04295704,  0.00699301,  0.02097902,\n",
       "        0.02697303,  0.001998  ,  0.001998  ,  0.003996  ,  0.001998  ,\n",
       "        0.06093906,  0.002997  ,  0.03596404,  0.01098901,  0.03996004,\n",
       "        0.11388611,  0.02797203,  0.00999001,  0.02597403,  0.000999  ,\n",
       "        0.00999001,  0.03296703,  0.05994006,  0.10589411,  0.002997  ,\n",
       "        0.05094905,  0.07792208,  0.07092907,  0.04495504,  0.01198801])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_comment('refund this is', word_to_index, topic_df_backer, topic_probs_df, tokenized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lda_backer[dictionary.doc2bow(['update'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.013853194148888517, u'support'),\n",
       " (0.013467743639179616, u'games'),\n",
       " (0.012870452281043583, u'tv'),\n",
       " (0.012834555530652294, u'not'),\n",
       " (0.012023936974385039, u'gamestick'),\n",
       " (0.012000473924815678, u'controller'),\n",
       " (0.011927891544576736, u'@'),\n",
       " (0.011853926240371983, u'android'),\n",
       " (0.011370823092772733, u'play'),\n",
       " (0.0099564992808737745, u\"'s\")]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_backer.show_topic(18, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0, p = 0.00299916\n",
      "topic 1, p = 0.0173392\n",
      "topic 2, p = 0.0903534\n",
      "topic 3, p = 0.0001078\n",
      "topic 4, p = 0.011089\n",
      "topic 5, p = 0.000119356\n",
      "topic 6, p = 0.0119999\n",
      "topic 7, p = 0.000124306\n",
      "topic 8, p = 0.000149237\n",
      "topic 9, p = 0.000102071\n",
      "topic 10, p = 0.17087\n",
      "topic 11, p = 0.000100648\n",
      "topic 12, p = 0.000127384\n",
      "topic 13, p = 0.000117164\n",
      "topic 14, p = 0.000111677\n",
      "topic 15, p = 0.251009\n",
      "topic 16, p = 0.0480157\n",
      "topic 17, p = 0.000106937\n",
      "topic 18, p = 0.00197673\n",
      "topic 19, p = 0.000119312\n",
      "topic 20, p = 0.0390278\n",
      "topic 21, p = 0.000109067\n",
      "topic 22, p = 0.000110008\n",
      "topic 23, p = 0.262581\n",
      "topic 24, p = 0.000129606\n",
      "topic 25, p = 0.0555829\n",
      "topic 26, p = 0.0108942\n",
      "topic 27, p = 0.000127714\n",
      "topic 28, p = 0.0243854\n",
      "topic 29, p = 0.000114463\n"
     ]
    }
   ],
   "source": [
    "p = get_top_probs('', word_to_index, topic_df_backer, topic_probs_df)\n",
    "for ii, x in enumerate(p):\n",
    "    print 'topic %d, p = %g' % (ii, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
